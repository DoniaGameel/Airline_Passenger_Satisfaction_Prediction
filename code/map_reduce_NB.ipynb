{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "import math\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load The Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd() \n",
    "relative_path_train = os.path.join('..', 'data', 'preprocessed_train_data.csv')\n",
    "relative_path_test = os.path.join('..', 'data', 'preprocessed_test_data.csv')\n",
    "\n",
    "preprocessed_train_data = pd.read_csv(os.path.join(current_dir, relative_path_train))\n",
    "preprocessed_test_data = pd.read_csv(os.path.join(current_dir, relative_path_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = preprocessed_train_data.drop([\"satisfaction\"], axis = 1)\n",
    "y_train = preprocessed_train_data[\"satisfaction\"]\n",
    "\n",
    "x_test = preprocessed_test_data.drop([\"satisfaction\"], axis = 1)\n",
    "y_test = preprocessed_test_data[\"satisfaction\"]\n",
    "\n",
    "#y_test = y_test.replace({\"satisfied\":1, \"neutral or dissatisfied\":0})\n",
    "\n",
    "k_fold = KFold(n_splits=10, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Apply Get Dummies Encoder on the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply get_dummies to train and test data\n",
    "train_encoded = pd.get_dummies(preprocessed_train_data)\n",
    "test_encoded = pd.get_dummies(preprocessed_test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scale The Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Scale the data\n",
    "scaler = MinMaxScaler()\n",
    "train_scaled = scaler.fit_transform(train_encoded)\n",
    "test_scaled = scaler.transform(test_encoded)\n",
    "\n",
    "# Convert scaled arrays back to DataFrame\n",
    "train_scaled_df = pd.DataFrame(train_scaled, columns=train_encoded.columns)\n",
    "test_scaled_df = pd.DataFrame(test_scaled, columns=test_encoded.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prior Probabilities**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prior Probability mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapper_prior_probability(data):\n",
    "    class_counts = {}\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        label = row[\"satisfaction\"]\n",
    "        if label not in class_counts:\n",
    "            class_counts[label] = 1\n",
    "        else:\n",
    "            class_counts[label] += 1\n",
    "\n",
    "    return [(class_counts, {})]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prior Probability reducer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reducer_prior_probability(mapped_results):\n",
    "    class_counts_total = {}\n",
    "\n",
    "    for c_count, _ in mapped_results:\n",
    "        for label, count in c_count.items():\n",
    "            if label not in class_counts_total:\n",
    "                class_counts_total[label] = count\n",
    "            else:\n",
    "                class_counts_total[label] += count\n",
    "\n",
    "    total_samples = sum(class_counts_total.values())\n",
    "    class_probabilities = {label: count / total_samples for label, count in class_counts_total.items()}\n",
    "\n",
    "    return class_probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Features Count**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "features count mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The mapper iterates over each row in the training data \n",
    "and counts occurrences of each feature-value pair for each class.\n",
    "'''\n",
    "def mapper(data):\n",
    "    feature_counts = {}\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        label = row[\"satisfaction\"]\n",
    "        for feature_name, feature_value in row.items():\n",
    "            if feature_name != \"satisfaction\":\n",
    "                key = (label, feature_name, feature_value)\n",
    "                if key not in feature_counts:\n",
    "                    feature_counts[key] = 1\n",
    "                else:\n",
    "                    feature_counts[key] += 1\n",
    "                    \n",
    "    return [feature_counts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "features count Reducer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "aggregates the counts from all mappers.\n",
    "sum up the counts for each class and each feature-value pair.\n",
    "'''\n",
    "def reducer(mapped_results):\n",
    "    feature_counts = {}\n",
    "\n",
    "    for f_count in mapped_results:\n",
    "        for key, count in f_count.items():\n",
    "            if key[0] not in feature_counts:\n",
    "                feature_counts[key[0]] = {}\n",
    "            if key[1] not in feature_counts[key[0]]:\n",
    "                feature_counts[key[0]][key[1]] = {}\n",
    "            feature_counts[key[0]][key[1]][key[2]] = count\n",
    "            \n",
    "    return feature_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train Naive Bayes Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapper_train_naive_bayes_feature_probabilities(feature_counts):\n",
    "    partial_feature_probabilities = []\n",
    "\n",
    "    for label, features in feature_counts.items():\n",
    "        partial_feature_probabilities.append((label, features))\n",
    "\n",
    "    return partial_feature_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reducer_train_naive_bayes_feature_probabilities(mapped_results):\n",
    "    feature_probabilities = {}\n",
    "\n",
    "    for label, features in mapped_results:\n",
    "        # Calculate feature probabilities\n",
    "        if label not in feature_probabilities:\n",
    "            feature_probabilities[label] = {}\n",
    "        for feature, values in features.items():\n",
    "            total_feature_count = sum(values.values())\n",
    "            if feature not in feature_probabilities[label]:\n",
    "                feature_probabilities[label][feature] = {}\n",
    "            for value, count in values.items():\n",
    "                if value not in feature_probabilities[label][feature]:\n",
    "                    feature_probabilities[label][feature][value] = count / total_feature_count\n",
    "                else:\n",
    "                    feature_probabilities[label][feature][value] += count / total_feature_count\n",
    "\n",
    "    return feature_probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make Predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "calculates the probability of each class for a given sample \n",
    "'''\n",
    "def mapper_predict_naive_bayes(class_probabilities, feature_probabilities, sample):\n",
    "    log_probs = {}\n",
    "\n",
    "    for label, class_prob in class_probabilities.items():\n",
    "        log_prob = math.log(class_prob)\n",
    "        for feature, value in sample.items():\n",
    "            if feature in feature_probabilities[label] and value in feature_probabilities[label][feature]:\n",
    "                log_prob += math.log(feature_probabilities[label][feature][value])\n",
    "            else:\n",
    "                # Handle unseen feature values\n",
    "                log_prob += 0\n",
    "        \n",
    "        log_probs[label] = log_prob\n",
    "\n",
    "    return log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "selects the class with the highest probability as the predicted class. \n",
    "'''\n",
    "def reducer_predict_naive_bayes(mapped_results):\n",
    "    predicted_class = None\n",
    "    max_log_prob = float('-inf')\n",
    "\n",
    "    for label, log_prob in mapped_results.items():\n",
    "        if log_prob > max_log_prob:\n",
    "            max_log_prob = log_prob\n",
    "            predicted_class = label\n",
    "\n",
    "    return predicted_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Apply Map Reducer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7626516019436653\n",
      "f1_score: 0.7399809573271012\n",
      "precision: 0.7018307199737296\n",
      "recall: 0.7825171624713959\n"
     ]
    }
   ],
   "source": [
    "# Mapping for Prior Probability\n",
    "mapped_results_prior = mapper_prior_probability(train_scaled_df)\n",
    "class_probabilities_prior = reducer_prior_probability(mapped_results_prior)\n",
    "\n",
    "# Mapping for Feature Counts\n",
    "mapped_results_feature_counts = mapper(train_scaled_df)\n",
    "final_feature_counts = reducer(mapped_results_feature_counts)\n",
    "\n",
    "# Apply map-reduce for Training Naive Bayes Classifier (Feature Probabilities)\n",
    "mapped_results_train_nb = mapper_train_naive_bayes_feature_probabilities(final_feature_counts)\n",
    "feature_probabilities = reducer_train_naive_bayes_feature_probabilities(mapped_results_train_nb)\n",
    "\n",
    "# Make predictions\n",
    "# Step 4: Make predictions\n",
    "predictions = []\n",
    "for index, row in test_scaled_df.iterrows():\n",
    "    sample = row.drop(\"satisfaction\").to_dict()\n",
    "    log_probs = mapper_predict_naive_bayes(class_probabilities_prior, feature_probabilities, sample)\n",
    "    predicted_class = reducer_predict_naive_bayes(log_probs)\n",
    "    predictions.append(predicted_class)\n",
    "\n",
    "\n",
    "# Evaluate the classifier\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "f1 = f1_score(y_test, predictions)\n",
    "precision = precision_score(y_test, predictions)\n",
    "recall = recall_score(y_test, predictions)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"f1_score:\", f1)\n",
    "print(\"precision:\", precision)\n",
    "print(\"recall:\", recall)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (geospatial)",
   "language": "python",
   "name": "geospatial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
