{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "import math\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load The Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd() \n",
    "relative_path_train = os.path.join('..', 'data', 'preprocessed_train_data.csv')\n",
    "relative_path_test = os.path.join('..', 'data', 'preprocessed_test_data.csv')\n",
    "\n",
    "preprocessed_train_data = pd.read_csv(os.path.join(current_dir, relative_path_train))\n",
    "preprocessed_test_data = pd.read_csv(os.path.join(current_dir, relative_path_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = preprocessed_train_data.drop([\"satisfaction\"], axis = 1)\n",
    "y_train = preprocessed_train_data[\"satisfaction\"]\n",
    "\n",
    "x_test = preprocessed_test_data.drop([\"satisfaction\"], axis = 1)\n",
    "y_test = preprocessed_test_data[\"satisfaction\"]\n",
    "\n",
    "#y_test = y_test.replace({\"satisfied\":1, \"neutral or dissatisfied\":0})\n",
    "\n",
    "k_fold = KFold(n_splits=10, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mapper**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Mapping\n",
    "'''\n",
    "iterates over each row in the training data and counts occurrences of each class and each feature-value pair.\n",
    "'''\n",
    "def mapper(data):\n",
    "    class_counts = {}\n",
    "    feature_counts = {}\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        label = row[\"satisfaction\"]\n",
    "        if label not in class_counts:\n",
    "            class_counts[label] = 1\n",
    "        else:\n",
    "            class_counts[label] += 1\n",
    "        for feature_name, feature_value in row.items():\n",
    "            if feature_name != \"satisfaction\":\n",
    "                key = (label, feature_name, feature_value)\n",
    "                if key not in feature_counts:\n",
    "                    feature_counts[key] = 1\n",
    "                else:\n",
    "                    feature_counts[key] += 1\n",
    "                    \n",
    "    return [(class_counts, feature_counts)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reducer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Reducing\n",
    "'''\n",
    "aggregates the counts from all mappers.\n",
    "sum up the counts for each class and each feature-value pair.\n",
    "'''\n",
    "def reducer(mapped_results):\n",
    "    class_counts = {}\n",
    "    feature_counts = {}\n",
    "\n",
    "    for c_count, f_count in mapped_results:\n",
    "        for label, count in c_count.items():\n",
    "            if label not in class_counts:\n",
    "                class_counts[label] = count\n",
    "            else:\n",
    "                class_counts[label] += count\n",
    "            \n",
    "        for key, count in f_count.items():\n",
    "            if key[0] not in feature_counts:\n",
    "                feature_counts[key[0]] = {}\n",
    "            if key[1] not in feature_counts[key[0]]:\n",
    "                feature_counts[key[0]][key[1]] = {}\n",
    "            feature_counts[key[0]][key[1]][key[2]] = count\n",
    "            \n",
    "    return (class_counts, feature_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train Naive Bayes Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Train the Naive Bayes classifier\n",
    "'''\n",
    "calculates probabilities based on the counts obtained from the mapper and reducer.\n",
    "calculates class probabilities and feature probabilities for each class and each feature-value pair.\n",
    "'''\n",
    "def train_naive_bayes(class_counts, feature_counts):\n",
    "    class_probabilities = {}\n",
    "    feature_probabilities = {}\n",
    "\n",
    "    total_samples = sum(class_counts.values())\n",
    "\n",
    "    # Calculate class probabilities\n",
    "    for label, count in class_counts.items():\n",
    "        class_probabilities[label] = count / total_samples\n",
    "\n",
    "    # Calculate feature probabilities\n",
    "    for label, features in feature_counts.items():\n",
    "        feature_probabilities[label] = {}\n",
    "        for feature, values in features.items():\n",
    "            total_feature_count = sum(values.values())\n",
    "            feature_probabilities[label][feature] = {value: count / total_feature_count for value, count in values.items()}\n",
    "\n",
    "    return class_probabilities, feature_probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make Predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Make predictions\n",
    "'''\n",
    "The prediction function calculates the probability of each class for a given sample \n",
    "sselects the class with the highest probability as the predicted class. \n",
    "'''\n",
    "def predict_naive_bayes(class_probabilities, feature_probabilities, sample, var_smoothing=1e-9):\n",
    "    predicted_class = None\n",
    "    max_log_prob = float('-inf')\n",
    "\n",
    "    for label, class_prob in class_probabilities.items():\n",
    "        log_prob = math.log(class_prob)\n",
    "        for feature, value in sample.items():\n",
    "            if feature in feature_probabilities[label] and value in feature_probabilities[label][feature]:\n",
    "                log_prob += math.log(feature_probabilities[label][feature][value] + var_smoothing)\n",
    "            else:\n",
    "                # Apply smoothing for unseen feature values\n",
    "                log_prob += math.log(var_smoothing)\n",
    "\n",
    "        if log_prob > max_log_prob:\n",
    "            max_log_prob = log_prob\n",
    "            predicted_class = label\n",
    "\n",
    "    return predicted_class\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Apply Map Reducer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7626516019436653\n",
      "f1_score: 0.7399809573271012\n",
      "precision: 0.7018307199737296\n",
      "recall: 0.7825171624713959\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Apply map-reduce\n",
    "mapped_results = mapper(preprocessed_train_data)\n",
    "final_class_counts, final_feature_counts = reducer(mapped_results)\n",
    "\n",
    "# Step 6: Train the Naive Bayes classifier\n",
    "class_probabilities, feature_probabilities = train_naive_bayes(final_class_counts, final_feature_counts)\n",
    "\n",
    "# Step 7: Make predictions\n",
    "predictions = []\n",
    "for index, row in preprocessed_test_data.iterrows():\n",
    "    sample = row.drop(\"satisfaction\").to_dict()\n",
    "    predicted_class = predict_naive_bayes(class_probabilities, feature_probabilities, sample)\n",
    "    predictions.append(predicted_class)\n",
    "\n",
    "# Step 8: Evaluate the classifier\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "f1 = f1_score(y_test, predictions)\n",
    "precision = precision_score(y_test, predictions)\n",
    "recall = recall_score(y_test, predictions)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"f1_score:\", f1)\n",
    "print(\"precision:\", precision)\n",
    "print(\"recall:\", recall)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (geospatial)",
   "language": "python",
   "name": "geospatial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
